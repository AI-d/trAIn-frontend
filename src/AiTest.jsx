import React, { useEffect, useRef, useState } from 'react';
import axios from "axios";

const AiTest = () => {
    const pcRef = useRef(null);
    const wsRef = useRef(null);
    const audioWs = useRef(null);
    const localStreamRef = useRef(null);
    const audioContextRef = useRef(null);

    // ì˜¤ë””ì˜¤ ì¬ìƒ í
    const audioQueueRef = useRef([]);
    const isPlayingRef = useRef(false);
    const nextStartTimeRef = useRef(0);

    const [connected, setConnected] = useState(false);
    const [isSpeaking, setIsSpeaking] = useState(false);
    const [isAiResponding, setIsAiResponding] = useState(false);
    const isSpeakingRef = useRef(false);

    /**
     * ì˜¤ë””ì˜¤ ì²­í¬ë¥¼ íì— ì¶”ê°€í•˜ê³  ì¬ìƒ
     */
    const playAudioQueue = async () => {
        if (isPlayingRef.current || audioQueueRef.current.length === 0) {
            return;
        }

        isPlayingRef.current = true;
        const audioContext = audioContextRef.current;

        if (!audioContext) {
            console.error("AudioContextê°€ ì—†ìŠµë‹ˆë‹¤");
            isPlayingRef.current = false;
            return;
        }

        try {
            while (audioQueueRef.current.length > 0) {
                const arrayBuffer = audioQueueRef.current.shift();

                // Int16 PCMì„ Float32ë¡œ ë³€í™˜
                const int16Array = new Int16Array(arrayBuffer);
                const float32Array = new Float32Array(int16Array.length);

                for (let i = 0; i < int16Array.length; i++) {
                    float32Array[i] = int16Array[i] / 32768.0;
                }

                // AudioBuffer ìƒì„±
                const audioBuffer = audioContext.createBuffer(
                    1,  // mono
                    float32Array.length,
                    48000  // sample rate
                );

                audioBuffer.getChannelData(0).set(float32Array);

                // ì¬ìƒ ì‹œê°„ ê³„ì‚° (ëŠê¹€ ì—†ì´ ì—°ì† ì¬ìƒ)
                const currentTime = audioContext.currentTime;
                const startTime = Math.max(currentTime, nextStartTimeRef.current);

                // ì¬ìƒ
                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(audioContext.destination);
                source.start(startTime);

                // ë‹¤ìŒ ì²­í¬ ì‹œì‘ ì‹œê°„ ê³„ì‚°
                nextStartTimeRef.current = startTime + audioBuffer.duration;

                console.log(`ğŸ”Š ì˜¤ë””ì˜¤ ì¬ìƒ: ${arrayBuffer.byteLength} bytes, ì‹œì‘: ${startTime.toFixed(3)}s`);

                // ì¬ìƒ ì™„ë£Œ ëŒ€ê¸°
                await new Promise(resolve => {
                    source.onended = resolve;
                });
            }

            console.log("âœ… ì˜¤ë””ì˜¤ ì¬ìƒ ì™„ë£Œ");
            setIsAiResponding(false);

        } catch (error) {
            console.error("âŒ ì˜¤ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨:", error);
        } finally {
            isPlayingRef.current = false;
        }
    };

    const initConnection = async () => {
        const scenarioId = 1;
        const userId = 1;

        try {
            console.log("ì„¸ì…˜ ìƒì„± ìš”ì²­ ì¤‘...");
            const response = await axios.post("http://localhost:9090/api/sessions", {
                userId: userId,
                scenarioId: scenarioId
            });

            const sessionId = response.data.data.sessionId;
            console.log("âœ… ì„¸ì…˜ ì•„ì´ë”” ìƒì„± ì™„ë£Œ:", sessionId);

            // AudioContext ìƒì„± (í•œ ë²ˆë§Œ)
            if (!audioContextRef.current) {
                audioContextRef.current = new AudioContext({ sampleRate: 48000 });
                console.log("âœ… AudioContext ìƒì„± ì™„ë£Œ");
            }

            // ---------------------------
            // 1. ì˜¤ë””ì˜¤ WS ì—°ê²°
            // ---------------------------
            audioWs.current = new WebSocket(`ws://localhost:9090/ws/audio/${sessionId}`);
            audioWs.current.binaryType = "arraybuffer";

            audioWs.current.onopen = () => {
                console.log("âœ… ì˜¤ë””ì˜¤ WS ì—°ê²°ë¨");

                // SESSION_INIT ì „ì†¡
                const initMessage = {
                    type: "SESSION_INIT",
                    scenarioId: scenarioId
                };
                console.log("ğŸ“¤ SESSION_INIT ì „ì†¡:", initMessage);
                audioWs.current.send(JSON.stringify(initMessage));
            };

            audioWs.current.onmessage = (event) => {
                if (event.data instanceof ArrayBuffer) {
                    console.log("ğŸ“¥ GPT ìŒì„± ì‘ë‹µ ìˆ˜ì‹ :", event.data.byteLength, "bytes");

                    // íì— ì¶”ê°€í•˜ê³  ì¬ìƒ
                    audioQueueRef.current.push(event.data);
                    playAudioQueue();
                }
            };

            audioWs.current.onerror = (error) => {
                console.error("âŒ ì˜¤ë””ì˜¤ WS ì—ëŸ¬:", error);
            };

            audioWs.current.onclose = () => {
                console.log("ğŸ”Œ ì˜¤ë””ì˜¤ WS ì¢…ë£Œ");
            };

            // ---------------------------
            // 2. ì‹œê·¸ë„ë§ WebSocket ì—°ê²°
            // ---------------------------
            wsRef.current = new WebSocket(`ws://localhost:9090/ws/signaling/${sessionId}`);

            wsRef.current.onopen = async () => {
                console.log("âœ… ì‹œê·¸ë„ë§ WS ì—°ê²°ë¨");
                setConnected(true);

                // ---------------------------
                // 3. RTCPeerConnection ìƒì„±
                // ---------------------------
                pcRef.current = new RTCPeerConnection({
                    iceServers: [{ urls: "stun:stun.l.google.com:19302" }],
                });

                // ë§ˆì´í¬ ì ‘ê·¼
                console.log("ğŸ¤ ë§ˆì´í¬ ì ‘ê·¼ ìš”ì²­...");
                const localStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true,
                        sampleRate: 48000
                    },
                    video: false
                });
                console.log("âœ… ë§ˆì´í¬ ì ‘ê·¼ ì„±ê³µ");
                localStreamRef.current = localStream;

                // Audio íŠ¸ë™ ì¶”ê°€
                localStream.getTracks().forEach((track) => {
                    pcRef.current.addTrack(track, localStream);
                });

                // ICE Candidate ì²˜ë¦¬
                pcRef.current.onicecandidate = (event) => {
                    if (event.candidate) {
                        console.log("ğŸ“¤ ICE Candidate ì „ì†¡");
                        wsRef.current.send(JSON.stringify({
                            type: "ICE_CANDIDATE",
                            candidate: event.candidate
                        }));
                    }
                };

                // Offer ìƒì„± ë° ì „ì†¡
                const offer = await pcRef.current.createOffer();
                await pcRef.current.setLocalDescription(offer);
                console.log("ğŸ“¤ Offer ì „ì†¡");
                wsRef.current.send(JSON.stringify({ type: "OFFER", sdp: offer.sdp }));

                // ---------------------------
                // 4. AudioWorklet ì„¤ì •
                // ---------------------------
                console.log("ğŸ”§ AudioWorklet ì„¤ì • ì‹œì‘...");
                const audioContext = audioContextRef.current;
                const source = audioContext.createMediaStreamSource(localStream);

                try {
                    await audioContext.audioWorklet.addModule('/audio-processor.js');
                    console.log("âœ… AudioWorklet ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ");

                    const workletNode = new AudioWorkletNode(audioContext, 'audio-processor');

                    workletNode.port.onmessage = (event) => {
                        if (!isSpeakingRef.current) return;

                        // Float32 -> Int16 ë³€í™˜
                        const float32Array = new Float32Array(event.data);
                        const int16Array = new Int16Array(float32Array.length);

                        for (let i = 0; i < float32Array.length; i++) {
                            const clamped = Math.max(-1, Math.min(1, float32Array[i]));
                            int16Array[i] = clamped * 32767;
                        }

                        // GPTë¡œ ìŒì„± ì „ì†¡
                        if (audioWs.current && audioWs.current.readyState === WebSocket.OPEN) {
                            audioWs.current.send(int16Array.buffer);
                        }
                    };

                    source.connect(workletNode);
                    console.log("âœ… AudioWorklet ì—°ê²° ì™„ë£Œ");
                } catch (error) {
                    console.error("âŒ AudioWorklet ì„¤ì • ì‹¤íŒ¨:", error);
                }
            };

            // ---------------------------
            // 5. ì‹œê·¸ë„ë§ ë©”ì‹œì§€ ì²˜ë¦¬
            // ---------------------------
            wsRef.current.onmessage = async (event) => {
                const data = JSON.parse(event.data);
                console.log("ğŸ“¥ ì‹œê·¸ë„ë§ ë©”ì‹œì§€:", data.type);

                if (data.type === "ANSWER") {
                    await pcRef.current.setRemoteDescription({
                        type: 'answer',
                        sdp: data.sdp,
                    });
                    console.log("âœ… Remote description ì„¤ì • ì™„ë£Œ");
                } else if (data.type === "ICE_CANDIDATE" && data.candidate) {
                    await pcRef.current.addIceCandidate(data.candidate);
                    console.log("âœ… ICE Candidate ì¶”ê°€");
                }
            };

            wsRef.current.onerror = (error) => {
                console.error("âŒ ì‹œê·¸ë„ë§ WS ì—ëŸ¬:", error);
            };

            wsRef.current.onclose = () => {
                console.log("ğŸ”Œ ì‹œê·¸ë„ë§ WS ì¢…ë£Œ");
                setConnected(false);
                audioWs.current?.close();
                pcRef.current?.close();
            };

        } catch (error) {
            console.error("âŒ ì—°ê²° ì´ˆê¸°í™” ì‹¤íŒ¨:", error);
            setConnected(false);
        }
    };

    const handleSpeakToggle = () => {
        if (!connected || isAiResponding) return;

        if (!isSpeaking) {
            // ë§í•˜ê¸° ì‹œì‘
            console.log("ğŸ™ ë§í•˜ê¸° ì‹œì‘");
            setIsSpeaking(true);
            isSpeakingRef.current = true;
        } else {
            // ë§í•˜ê¸° ì¢…ë£Œ
            console.log("ğŸ›‘ ë§í•˜ê¸° ì¢…ë£Œ");
            setIsSpeaking(false);
            isSpeakingRef.current = false;

            if (audioWs.current && audioWs.current.readyState === WebSocket.OPEN) {
                audioWs.current.send(JSON.stringify({ type: "speech.end" }));
                console.log("ğŸ“¤ speech.end ì „ì†¡ ì™„ë£Œ");
                setIsAiResponding(true);

                // ì˜¤ë””ì˜¤ í ì´ˆê¸°í™”
                audioQueueRef.current = [];
                nextStartTimeRef.current = 0;
            }
        }
    };

    const closeConnection = () => {
        console.log("ğŸ”Œ ì—°ê²° ì¢…ë£Œ ì‹œì‘...");

        // WebSocket ì¢…ë£Œ
        wsRef.current?.close();
        audioWs.current?.close();

        // RTCPeerConnection ì¢…ë£Œ
        pcRef.current?.close();

        // ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ
        if (localStreamRef.current) {
            localStreamRef.current.getTracks().forEach(track => track.stop());
        }

        // AudioContext ì¢…ë£Œ
        if (audioContextRef.current) {
            audioContextRef.current.close();
            audioContextRef.current = null;
        }

        // ìƒíƒœ ì´ˆê¸°í™”
        setConnected(false);
        setIsSpeaking(false);
        setIsAiResponding(false);
        isSpeakingRef.current = false;
        isPlayingRef.current = false;
        audioQueueRef.current = [];
        nextStartTimeRef.current = 0;

        console.log("âœ… ì—°ê²° í•´ì œ ì™„ë£Œ");
    };

    useEffect(() => {
        return () => {
            closeConnection();
        };
    }, []);

    return (
        <div style={{ padding: 20, fontFamily: "Arial, sans-serif" }}>
            <h2>ğŸ§ GPT Realtime ëŒ€í™” í…ŒìŠ¤íŠ¸</h2>

            {/* ì—°ê²° ë²„íŠ¼ */}
            <div style={{ display: "flex", gap: 10, marginBottom: 20 }}>
                <button
                    onClick={initConnection}
                    disabled={connected}
                    style={{
                        padding: "10px 20px",
                        backgroundColor: connected ? "#ccc" : "#4CAF50",
                        color: "white",
                        border: "none",
                        borderRadius: 4,
                        cursor: connected ? "not-allowed" : "pointer"
                    }}
                >
                    ğŸš€ ì—°ê²°
                </button>

                <button
                    onClick={closeConnection}
                    disabled={!connected}
                    style={{
                        padding: "10px 20px",
                        backgroundColor: !connected ? "#ccc" : "#f44336",
                        color: "white",
                        border: "none",
                        borderRadius: 4,
                        cursor: !connected ? "not-allowed" : "pointer"
                    }}
                >
                    ğŸ›‘ í•´ì œ
                </button>

                <span>
                    ìƒíƒœ:{" "}
                    {connected ? (
                        <b style={{ color: "green" }}>â— ì—°ê²°ë¨</b>
                    ) : (
                        <b style={{ color: "gray" }}>â—‹ ì—°ê²° ì•ˆë¨</b>
                    )}
                </span>
            </div>

            {/* ë§í•˜ê¸° ë²„íŠ¼ */}
            <div
                style={{
                    display: "flex",
                    flexDirection: "column",
                    gap: "15px",
                    alignItems: "center",
                    marginTop: 20,
                }}
            >
                <button
                    onClick={handleSpeakToggle}
                    disabled={!connected || isAiResponding}
                    style={{
                        width: 150,
                        height: 150,
                        borderRadius: "50%",
                        fontSize: 20,
                        border: "none",
                        color: "white",
                        backgroundColor: isSpeaking
                            ? "#f44336"
                            : isAiResponding
                                ? "#2196F3"
                                : "#4CAF50",
                        cursor: connected && !isAiResponding ? "pointer" : "not-allowed",
                        transition: "all 0.3s ease"
                    }}
                >
                    {isSpeaking
                        ? "ğŸ—£ ë§í•˜ëŠ” ì¤‘"
                        : isAiResponding
                            ? "ğŸ¤– ì‘ë‹µ ì¤‘"
                            : "ğŸ¤ ëˆŒëŸ¬ì„œ ë§í•˜ê¸°"}
                </button>

                <p style={{ color: "#666", fontSize: 14 }}>
                    {isSpeaking && "ë²„íŠ¼ì„ ë‹¤ì‹œ ëˆŒëŸ¬ ë§í•˜ê¸°ë¥¼ ì¢…ë£Œí•˜ì„¸ìš”"}
                    {isAiResponding && "AIê°€ ì‘ë‹µí•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."}
                    {!isSpeaking && !isAiResponding && connected && "ë²„íŠ¼ì„ ëˆŒëŸ¬ ë§í•˜ê¸°ë¥¼ ì‹œì‘í•˜ì„¸ìš”"}
                </p>
            </div>
        </div>
    );
};

export default AiTest;
